{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uFsBlyxwmRq2"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 DeepMind Technologies Limited\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmw6HSr7xZvZ"
   },
   "outputs": [],
   "source": [
    "# Install dependencies for Google Colab.\n",
    "# If you want to run this notebook on your own machine, you can skip this cell\n",
    "\n",
    "!mkdir ./perceiver\n",
    "!touch ./perceiver/__init__.py\n",
    "!wget -O ./perceiver/bytes_tokenizer.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/bytes_tokenizer.py\n",
    "!wget -O ./perceiver/io_processors.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/io_processors.py\n",
    "!wget -O ./perceiver/perceiver.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/perceiver.py\n",
    "!wget -O ./perceiver/position_encoding.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/position_encoding.py\n",
    "!wget -O language_perceiver_io_bytes.pickle https://storage.googleapis.com/perceiver_io/language_perceiver_io_bytes.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-14 17:45:04--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/autoaugment.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 25589 (25K) [text/plain]\r\n",
      "Saving to: ‘./train/autoaugment.py’\r\n",
      "\r\n",
      "./train/autoaugment 100%[===================>]  24.99K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2022-03-14 17:45:05 (78.2 MB/s) - ‘./train/autoaugment.py’ saved [25589/25589]\r\n",
      "\r\n",
      "--2022-03-14 17:45:05--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/dataset.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 14996 (15K) [text/plain]\r\n",
      "Saving to: ‘./train/dataset.py’\r\n",
      "\r\n",
      "./train/dataset.py  100%[===================>]  14.64K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2022-03-14 17:45:06 (54.3 MB/s) - ‘./train/dataset.py’ saved [14996/14996]\r\n",
      "\r\n",
      "--2022-03-14 17:45:06--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/experiment.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 18810 (18K) [text/plain]\r\n",
      "Saving to: ‘./train/experiment.py’\r\n",
      "\r\n",
      "./train/experiment. 100%[===================>]  18.37K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2022-03-14 17:45:06 (60.0 MB/s) - ‘./train/experiment.py’ saved [18810/18810]\r\n",
      "\r\n",
      "--2022-03-14 17:45:07--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/utils.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 7940 (7.8K) [text/plain]\r\n",
      "Saving to: ‘./train/utils.py’\r\n",
      "\r\n",
      "./train/utils.py    100%[===================>]   7.75K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2022-03-14 17:45:07 (38.3 MB/s) - ‘./train/utils.py’ saved [7940/7940]\r\n",
      "\r\n",
      "--2022-03-14 17:45:08--  https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/launch_local.sh\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 768 [text/plain]\r\n",
      "Saving to: ‘./train/launch_local.sh’\r\n",
      "\r\n",
      "./train/launch_loca 100%[===================>]     768  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2022-03-14 17:45:08 (42.6 MB/s) - ‘./train/launch_local.sh’ saved [768/768]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the examples of training a Perceiver\n",
    "\n",
    "!mkdir ./train\n",
    "!touch ./train/__init__.py\n",
    "!wget -O ./train/autoaugment.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/autoaugment.py\n",
    "!wget -O ./train/dataset.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/dataset.py\n",
    "!wget -O ./train/experiment.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/experiment.py\n",
    "!wget -O ./train/utils.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/utils.py\n",
    "!wget -O ./train/launch_local.sh https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/train/launch_local.sh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "IBVh06qUojjm"
   },
   "outputs": [],
   "source": [
    "#@title Import\n",
    "from typing import Union\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from perceiver import perceiver, position_encoding, io_processors, bytes_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "sFa-lRuVfKZt"
   },
   "outputs": [],
   "source": [
    "#@title Load parameters from checkpoint\n",
    "\n",
    "with open(\"language_perceiver_io_bytes.pickle\", \"rb\") as f:\n",
    "  params = pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "id": "LBzQQ7t_VCBo"
   },
   "outputs": [],
   "source": [
    "#@title Model config\n",
    "D_MODEL = 768\n",
    "D_LATENTS = 1280\n",
    "MAX_SEQ_LEN = 2048\n",
    "\n",
    "encoder_config = dict(\n",
    "    num_self_attends_per_block=26,\n",
    "    num_blocks=1,\n",
    "    z_index_dim=256,\n",
    "    num_z_channels=D_LATENTS,\n",
    "    num_self_attend_heads=8,\n",
    "    num_cross_attend_heads=8,\n",
    "    qk_channels=8 * 32,\n",
    "    v_channels=D_LATENTS,\n",
    "    use_query_residual=True,\n",
    "    cross_attend_widening_factor=1,\n",
    "    self_attend_widening_factor=1)\n",
    "\n",
    "decoder_config = dict(\n",
    "    output_num_channels=D_LATENTS,\n",
    "    position_encoding_type='trainable',\n",
    "    output_index_dims=MAX_SEQ_LEN,\n",
    "    num_z_channels=D_LATENTS,\n",
    "    qk_channels=8 * 32,\n",
    "    v_channels=D_MODEL,\n",
    "    num_heads=8,\n",
    "    final_project=False,\n",
    "    use_query_residual=False,\n",
    "    trainable_position_encoding_kwargs=dict(num_channels=D_MODEL))\n",
    "\n",
    "# The tokenizer is just UTF-8 encoding (with an offset)\n",
    "tokenizer = bytes_tokenizer.BytesTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "id": "EWOeFoF0aCaT"
   },
   "outputs": [],
   "source": [
    "#@title Decoding Perceiver Model\n",
    "def apply_perceiver(\n",
    "    inputs: jnp.ndarray, input_mask: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Runs a forward pass on the Perceiver.\n",
    "\n",
    "  Args:\n",
    "    inputs: input bytes, an int array of shape [B, T]\n",
    "    input_mask: Array of shape indicating which entries are valid and which are\n",
    "      masked. A truthy value indicates that the entry is valid.\n",
    "\n",
    "  Returns:\n",
    "    The output logits, an array of shape [B, T, vocab_size].\n",
    "  \"\"\"\n",
    "  assert inputs.shape[1] == MAX_SEQ_LEN\n",
    "\n",
    "  embedding_layer = hk.Embed(\n",
    "      vocab_size=tokenizer.vocab_size,\n",
    "      embed_dim=D_MODEL)\n",
    "  embedded_inputs = embedding_layer(inputs)\n",
    "\n",
    "  batch_size = embedded_inputs.shape[0]\n",
    "\n",
    "  input_pos_encoding = perceiver.position_encoding.TrainablePositionEncoding(\n",
    "      index_dim=MAX_SEQ_LEN, num_channels=D_MODEL)\n",
    "  embedded_inputs = embedded_inputs + input_pos_encoding(batch_size)\n",
    "  perceiver_mod = perceiver.Perceiver(\n",
    "      encoder=perceiver.PerceiverEncoder(**encoder_config),\n",
    "      decoder=perceiver.BasicDecoder(**decoder_config))\n",
    "  output_embeddings = perceiver_mod(\n",
    "      embedded_inputs, is_training=False, input_mask=input_mask, query_mask=input_mask)\n",
    "\n",
    "  logits = io_processors.EmbeddingDecoder(\n",
    "      embedding_matrix=embedding_layer.embeddings)(output_embeddings)\n",
    "  return logits\n",
    "\n",
    "apply_perceiver = hk.transform(apply_perceiver).apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Pna1ZXEyOJZb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string without masked bytes:\n",
      "This is an incomplete sentence where some are missing.\n"
     ]
    }
   ],
   "source": [
    "input_str = \"This is an incomplete sentence where some words are missing.\"\n",
    "input_tokens = tokenizer.to_int(input_str)\n",
    "\n",
    "qstart = 42\n",
    "qend = 48\n",
    "\n",
    "# Mask \" missing.\". Note that the model performs much better if the masked chunk\n",
    "# starts with a space.\n",
    "input_tokens[qstart:qend] = tokenizer.mask_token\n",
    "print(\"Tokenized string without masked bytes:\")\n",
    "print(tokenizer.to_string(input_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "id": "6TCMuVUabnTg"
   },
   "outputs": [],
   "source": [
    "#@title Pad and reshape inputs\n",
    "inputs = input_tokens[None]\n",
    "input_mask = np.ones_like(inputs)\n",
    "\n",
    "def pad(max_sequence_length: int, inputs, input_mask):\n",
    "  input_len = inputs.shape[1]\n",
    "  assert input_len <= max_sequence_length\n",
    "  pad_len = max_sequence_length - input_len\n",
    "  padded_inputs = np.pad(\n",
    "      inputs,\n",
    "      pad_width=((0, 0), (0, pad_len)),\n",
    "      constant_values=tokenizer.pad_token)\n",
    "  padded_mask = np.pad(\n",
    "      input_mask,\n",
    "      pad_width=((0, 0), (0, pad_len)),\n",
    "      constant_values=0)\n",
    "  return padded_inputs, padded_mask\n",
    "\n",
    "inputs, input_mask = pad(MAX_SEQ_LEN, inputs, input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 2048)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_mask.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ipZs6p0Xk3lb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy predictions:\n",
      "[ 38 125 117 120 106 121]\n",
      "\n",
      "Predicted string:\n",
      " words\n"
     ]
    }
   ],
   "source": [
    "from apply_perceiver import apply_perceiver\n",
    "\n",
    "rng = jax.random.PRNGKey(1)  # Unused\n",
    "\n",
    "out = apply_perceiver(params, rng=rng, inputs=inputs, input_mask=input_mask, tokenizer=tokenizer,\n",
    "                      encoder_config=encoder_config, decoder_config=decoder_config)\n",
    "\n",
    "masked_tokens_predictions = out[0, qstart:qend].argmax(axis=-1)\n",
    "print(\"Greedy predictions:\")\n",
    "print(masked_tokens_predictions)\n",
    "print()\n",
    "print(\"Predicted string:\")\n",
    "print(tokenizer.to_string(masked_tokens_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'                                           words            aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.to_string( out[0].argmax(axis=-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DeviceArray([ 38,  38, 125, 117, 120, 106, 121,  38,  38,  38,  38,  38,\n              38,  38,  38,  38,  38,  38,  38, 103, 103, 103, 103, 103,\n             103, 103, 103, 103, 103], dtype=int32)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0, 41:70].argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Perceiver IO: Masked Language Modelling",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "perceiver_py38",
   "language": "python",
   "name": "perceiver_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}